//
// Created by 20212 on 24-12-9.
//
/*
 *
 *1个文件有100亿个int，1g内存，设计算法找到出现次数不超过2次的所有整数
 *本题跟1题的思路是一样的
 *本题找到是不超过2次的，也就是要找出1次和2次的
 *本题还是用两个位来标记，分为出现0次 00 表示，出现1次的 01 表示 出现2次的 10 表示 出现3次及3次以上的 11 表示
 *位图只能处理整数
 *布隆过滤器
 *分析：（query一般就是sql查询语句或者网络请求的url，一般是一个字符串）
 *1.给两个文件，分别有100亿个query，我们只有1g内存，如何找到两个文件的交集 分别给出精确算法和近似算法
 *2.如何扩展bloomfilter，使其支持删除操作
 *100亿个query占用多少查询 假设平均一个query 30-60byte，100亿个query占用300 - 600g内存
 *1.方案一：将文件一中的query映射到布隆过滤器，读取文件2中的query，判断在不在布隆过滤器中，在就是交集
 *方案一缺陷：交集中有些数不准确，还是有些交集的数据漏掉了
 *布隆过滤器判断在是准确的还是不在是准确的
 *判断不在是准确的
 *2.每个位标记成计数器
 *那么到底用几个位来表示计数器呢 给的位如果少了，如果多个值映射到一个位置就会导致计数器溢出
 *比如1个byte最多计数到256 假设有260个值映射到一个位置，那么就出问题了
 *但是如果使用的更多的位映射一个位置，那么空间消耗就大了，不要忘记布隆过滤器的特点就是节省空间.
 *1.方案二 精确解法
 *文件很大，不能都放到内存中，那么我们可以把文件切分成多个小文件，小文件数据加载到内存当中
 *A0   A1   A2   A999
 *B0   B1   B2   B999
 * 切分成多少份:一般切出来一个小文件的大小可以放进内存就可以。那么这里一个文件300-600g，那么切分成1000份 一个文件300-600m
 * 如果是平均切分，a0可以放到内存中存储一个set，那么b0-b999都得跟a0比较，那么就是1000次比较
 * 优势是 部分空间放在set中，可以快速比较，缺点是比较次数多
 *哈希切分:i = hashstr(query) % 1000
 *i是多少 query就进入第Ai/Bi,文件a和文件b分别这么处理
 *将ai放小文件的数据放到一个set中，读取对应的bi小文件中的query，看在不在ai中，在就是交集
 *a 和 b中相同的一定进入相同编号的Ai和Bi
 *
*/